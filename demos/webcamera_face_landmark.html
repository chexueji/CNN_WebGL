<!doctype html>
<html>
<head>
    <meta charset='UTF-8'>
    <meta name='viewport'
          content='width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0'>
    <title>FaceDetection Demo</title>
    <style type='text/css'>
        #fps {
            position: absolute;
            left: 0px;
            right: 0px;
            width: 100px;
            height: 20px;
            background-color: #686868;
            font-size: 50%;
            color: #00FF00;
            text-align: left;
            opacity: 0.7;
            filter: alpha(opacity=70);
        }

        #cnn {
            position: absolute;
            left: 0px;
            right: 0px;
            width: 100px;
            height: 20px;
            background-color: #686868;
            font-size: 50%;
            color: #00FF00;
            text-align: left;
            opacity: 0.7;
            filter: alpha(opacity=70);
        }

        .footer {
            position: fixed;
            left: 0;
            bottom: 0;
            width: 100%;
            color: black;
        }

        .footer-text {
            max-width: 600px;
            text-align: center;
            margin: auto;
        }

        body {
            text-align: center;
        }
    </style>
</head>
<!--<body onload='main()'>-->
<body>
<div id='info' style='display:none'>
</div>
<div id='loading' style='display:block'>
    Loading the model...
</div>
<div id='main' style='display:none; position: relative; width:256px; height:256px; margin: 0 auto; '>
    <video id='video' style=' -moz-transform: scaleX(-1);
             -o-transform: scaleX(-1);
             -webkit-transform: scaleX(-1);
            transform: scaleX(-1);
            display: none;
            '>
    </video>
    <canvas id='output'></canvas>
    <div id='fps'
         style='position: absolute; top: 0px; left: 0px; opacity: 0.7; height: 20px; width: 100px;display: none;'>fps:
    </div>
    <div id='cnn'
         style='position: absolute; top: 21px; left: 0px; opacity: 0.7; height: 20px; width: 100px;display: none;'>cnn:0
        ms
    </div>
</div>
<div id='detect' style='display:block'>
    <p>
        <button type='button' onclick='main()'>Detect</button>
    </p>
</div>

<div class='footer'>
    <div class='footer-text'>
        <p>
            Face Detection Demo with a <strong>single-face</strong> detection algorithm.
            <br>
            <br> 此为人脸LandMark检测Demo.
        </p>
    </div>
</div>
</body>
<script type='module'>

    import {NetworkBuilder} from "../src/net/netbuilder.js";
    import {NetRunner} from "../src/net/netrunner.js";
    import {Stats} from "../src/common/stats.js";
    import {Vector2D} from "../src/common/types.js";
    import * as Utils from "../src/common/utils.js"

    function detectFace(video, videoWidth, videoHeight, networkBuilder, gl) {
        const canvas = document.getElementById('output');
        const ctx = canvas.getContext('2d', {antialias: false});
        window.fps = document.getElementById('fps');
        window.cnn = document.getElementById('cnn');

        canvas.width = videoWidth;
        canvas.height = videoHeight;
        let videoChannel = 3;
        let modelInputChannel = 1;
        let modelInputWidth = 128;
        let modelInputHeight = 128;

        let stats = new Stats();
        let packed = false;
        let network = networkBuilder.network;
        //Landmark input range [0.0-4.0]
        let input_scale = 4.0;
        let input_trans = 0.0;

        let runner = new NetRunner(gl, packed, input_scale, input_trans);
        runner.set_input(videoChannel, videoHeight, videoWidth, modelInputChannel, modelInputHeight, modelInputWidth, network);
        console.log('face landmark detect begin!');

        async function faceDetectRender() {
            ctx.clearRect(0, 0, videoWidth, videoHeight);
            //show video
            ctx.save();
            ctx.scale(-1, 1);
            ctx.translate(-videoWidth, 0);
            stats.begin();
            ctx.drawImage(video, 0, 0, videoWidth, videoHeight);
            stats.end();
            // console.log('draw image time:' + stats.RunTime.toFixed(3) + ' ms');
            ctx.restore();
            stats.begin();
            let data = ctx.getImageData(0, 0, videoWidth, videoHeight);
            stats.end();
            // console.log('get image time:' + stats.RunTime.toFixed(3) + 'ms');
            // run network
            runner.run(data, network);
            // post process
            let t_landmark_post_st = performance.now();
            let landmark_out = network.getOutputByName("v_197");
            let classes_out = network.getOutputByName("v_208");
            let landmark_feature = landmark_out.rawData();
            let classes_feature = classes_out.rawData();

            let sum_exp = 0.0;
            for (let cls_id = 0; cls_id < 2; cls_id++) {
                classes_feature[cls_id] = Math.exp(classes_feature[cls_id]);
                sum_exp += classes_feature[cls_id];
            }

            for (let i = 0; i < classes_feature.length; i++) {
                classes_feature[i] /= sum_exp;
            }

            let landmarks = new Array();
            for(let i = 0;i < landmark_feature.length; i += 2)
            {
                let point = new Vector2D(landmark_feature[i]/64.0,landmark_feature[i+1]/64.0);
                landmarks.push(point);
            }
            let t_landmark_post_ed = performance.now();
            window.cnn.innerHTML = 'cnn: ' + (t_landmark_post_ed - t_landmark_post_st).toFixed(1) + ' ms';

            if(classes_feature[1] > 0.5) {
                for (let i = 0; i < landmarks.length; i++) {
                    let landmark = landmarks[i];
                    Utils.drawPoint(ctx, videoWidth * landmark.x, videoHeight * landmark.y, 4, 'red');
                }
            }

            stats.updateFPS();
            fps.innerHTML = 'fps: ' + stats.FPS + '->' + stats.ElapsedTime + ' ms';
            requestAnimationFrame(faceDetectRender);
        }

        faceDetectRender();
    }


    function main() {

        const videoWidth = 512;
        const videoHeight = 512;

        let gl = Utils.checkWebGL();
        if (!gl)
            return;
        Utils.checkBrowerSupport();

        window.navigator.getUserMedia = navigator.getUserMedia ||
            navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;

        let packed = false;
        let nb = new NetworkBuilder(gl, packed);
        nb.buildFromUrl('../src/models/landmarks/test.m', async function () {
            //nb.network.rebuild();
            document.getElementById('loading').style.display = 'none';
            document.getElementById('main').style.display = 'block';
            document.getElementById('detect').style.display = 'none';

            let video;
            try {
                video = await Utils.loadVideo(videoWidth, videoHeight);
            } catch (e) {
                let info = document.getElementById('info');
                info.textContent = 'This browser does not support video capture, or this device does not have a camera';
                info.style.display = 'block';
                throw e;
            }
            document.getElementById('fps').style.display = 'block';
            document.getElementById('cnn').style.display = 'block';
            detectFace(video, videoWidth, videoHeight, nb, gl);
        });
    }

    main();
</script>
</html>
